Feature:Azure Data Ingest
  I want to ingest data
  so that it is available in Azure data lake storage

  Scenario Outline: Data Factory Ingest SQL Database into ADLS
    Given the ADF pipeline Ingest_AzureSql_{{ source_name }} has been triggered with <parameters>
    And I poll the pipeline every {{ adf_pipeline_status_check_interval_seconds }} seconds until it has completed
    And the ADF pipeline Ingest_AzureSql_{{ source_name }} has finished with state Succeeded
    And the ADF pipeline completed in less than {{ adf_pipeline_timeout_seconds }} seconds
    Then the files <output_files> are present in the ADLS container {{ bronze_container }} in the directory Ingest_AzureSql_{{ source_name }}

    Examples: Output files
    |parameters|output_files|
    |{"window_start" : "{{ window_start_default }}", "window_end": "{{ window_end_default }}"}|[{% for entity in ingest_entities if entity.enabled and ingest_source_enabled %}"{{ entity.display_name }}.parquet"{% if not loop.last %}, {% endif %}{% endfor %}]|
