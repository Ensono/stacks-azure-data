# Reusable template for Terraform deployment steps
parameters:
  - name: stage_name
    type: string
  - name: tf_backend_key
    type: string
  - name: download_artifact
    type: string
    default: ""
  - name: artifact_file
    type: string
    default: ""
  - name: destroy
    type: boolean
    default: false
  - name: deploy
    type: boolean
    default: true

steps:
  - task: Bash@3
    displayName: "Cleanup: Remove .terraform directories"
    inputs:
      targetType: inline
      script: |
        echo "Cleaning workspace..."
        sudo rm -rf $(Build.SourcesDirectory)/deploy/terraform/*/.terraform
    continueOnError: true

  - checkout: self
    clean: true

  - ${{ if ne(parameters.download_artifact, '') }}:
      - task: DownloadPipelineArtifact@2
        displayName: "Download ${{ parameters.download_artifact }} artifacts"
        inputs:
          buildType: current
          artifactName: ${{ parameters.download_artifact }}
          targetPath: $(Agent.TempDirectory)/${{ parameters.download_artifact }}
        continueOnError: true

  - template: install-eirctl.yml
    parameters:
      EirctlVersion: $(EirctlVersion)

  - task: Cache@2
    displayName: "Cache: Docker image"
    inputs:
      key: 'docker | "$(Agent.OS)" | "ensono/eir-infrastructure" | "$(EirctlVersion)"'
      path: $(Pipeline.Workspace)/.docker-cache
      cacheHitVar: DOCKER_CACHE_RESTORED

  - task: Bash@3
    displayName: "Docker: Restore cached image"
    condition: eq(variables.DOCKER_CACHE_RESTORED, 'true')
    inputs:
      targetType: inline
      script: |
        if [ -f $(Pipeline.Workspace)/.docker-cache/eir-infrastructure.tar ]; then
          echo "Loading cached Docker image..."
          docker load -i $(Pipeline.Workspace)/.docker-cache/eir-infrastructure.tar
          echo "Cached image loaded successfully"
        fi

  - task: Bash@3
    displayName: "Eirctl: Initialise Terraform"
    inputs:
      targetType: inline
      script: |
        export USER_ID=`id -u`
        export USER_GROUP_ID=`id -g`
        eirctl -d infra:init
    env:
      ARM_CLIENT_ID: $(ARM_CLIENT_ID)
      ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
      ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
      ARM_TENANT_ID: $(ARM_TENANT_ID)
      TF_BACKEND_INIT: "key=${{ parameters.tf_backend_key }},storage_account_name=$(tf_state_storage),resource_group_name=$(tf_state_rg),container_name=$(tf_state_container)"

  - ${{ if and(ne(parameters.download_artifact, ''), ne(parameters.artifact_file, '')) }}:
      - task: CopyFiles@2
        displayName: "Copy Terraform Variables file"
        inputs:
          SourceFolder: $(Agent.TempDirectory)/${{ parameters.download_artifact }}/
          Contents: "${{ parameters.artifact_file }}"
          TargetFolder: $(Build.SourcesDirectory)/deploy/terraform/${{ parameters.stage_name }}
        continueOnError: true

  - ${{ if eq(parameters.destroy, true) }}:
      - task: Bash@3
        displayName: "Terraform: Extract variables from state for destroy"
        inputs:
          targetType: inline
          script: |
            cd $(Build.SourcesDirectory)/deploy/terraform/${{ parameters.stage_name }}

            # Create a minimal tfvars file from state outputs if artifact wasn't available
            if [ ! -f *.auto.tfvars ]; then
              echo "No tfvars file found, attempting to extract from state..."

              # Initialize terraform to access state
              export USER_ID=`id -u`
              export USER_GROUP_ID=`id -g`

              # For databricks, we need to query the infra state for required variables
              if [ "${{ parameters.stage_name }}" == "databricks" ]; then
                echo "Querying infrastructure state for Databricks variables..."

                # Get terraform state from infrastructure
                cd $(Build.SourcesDirectory)/deploy/terraform/infra

                # Pull latest state
                terraform init -backend-config="key=$(company)-$(project)-$(domain)-infra" \
                  -backend-config="storage_account_name=$(tf_state_storage)" \
                  -backend-config="resource_group_name=$(tf_state_rg)" \
                  -backend-config="container_name=$(tf_state_container)" > /dev/null 2>&1 || true

                # Extract outputs
                ADB_HOST=$(terraform output -raw adb_databricks_hosturl 2>/dev/null || echo "")
                ADB_ID=$(terraform output -raw adb_databricks_id 2>/dev/null || echo "")
                KV_ID=$(terraform output -raw key_vault_id 2>/dev/null || echo "")
                KV_URI=$(terraform output -raw key_vault_uri 2>/dev/null || echo "")

                # Go back to databricks dir and create tfvars
                cd $(Build.SourcesDirectory)/deploy/terraform/databricks

                if [ -n "$ADB_HOST" ] && [ -n "$ADB_ID" ]; then
                  cat > destroy-temp.auto.tfvars << 'EOFVARS'
            adb_databricks_hosturl = "$ADB_HOST"
            adb_databricks_id = "$ADB_ID"
            key_vault_id = "$KV_ID"
            key_vault_uri = "$KV_URI"
            EOFVARS
                  # Substitute variables
                  sed -i "s|\$ADB_HOST|$ADB_HOST|g" destroy-temp.auto.tfvars
                  sed -i "s|\$ADB_ID|$ADB_ID|g" destroy-temp.auto.tfvars
                  sed -i "s|\$KV_ID|$KV_ID|g" destroy-temp.auto.tfvars
                  sed -i "s|\$KV_URI|$KV_URI|g" destroy-temp.auto.tfvars
                  echo "Created temporary tfvars from infrastructure state"
                  cat destroy-temp.auto.tfvars
                else
                  echo "Warning: Could not extract variables from state, destroy may fail"
                fi
              fi
            else
              echo "Tfvars file exists, using it for destroy"
            fi
        env:
          ARM_CLIENT_ID: $(ARM_CLIENT_ID)
          ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
          ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
          ARM_TENANT_ID: $(ARM_TENANT_ID)
        continueOnError: true

      - task: Bash@3
        displayName: "Eirctl: [DESTROY] Plan ${{ parameters.stage_name }}"
        inputs:
          targetType: inline
          script: |
            eirctl infra:destroy:plan
        env:
          ARM_CLIENT_ID: $(ARM_CLIENT_ID)
          ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
          ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
          ARM_TENANT_ID: $(ARM_TENANT_ID)
          TF_VAR_name_company: $(company)
          TF_VAR_name_project: $(project)
          TF_VAR_ado_org_url: $(ado_org_url)
          TF_VAR_ado_project_id: $(ado_project_id)

      - task: Bash@3
        displayName: "Eirctl: [DESTROY] Apply ${{ parameters.stage_name }}"
        inputs:
          targetType: inline
          script: |
            eirctl infra:destroy:apply
        env:
          ARM_CLIENT_ID: $(ARM_CLIENT_ID)
          ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
          ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
          ARM_TENANT_ID: $(ARM_TENANT_ID)

  - ${{ if eq(parameters.deploy, true) }}:
      - task: Bash@3
        displayName: "Eirctl: Plan ${{ parameters.stage_name }}"
        inputs:
          targetType: inline
          script: |
            eirctl -d infra:plan
        env:
          ARM_CLIENT_ID: $(ARM_CLIENT_ID)
          ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
          ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
          ARM_TENANT_ID: $(ARM_TENANT_ID)
          TF_VAR_name_company: $(company)
          TF_VAR_name_project: $(project)
          TF_VAR_ado_org_url: $(ado_org_url)
          TF_VAR_ado_project_id: $(ado_project_id)

      - task: Bash@3
        displayName: "Eirctl: Apply ${{ parameters.stage_name }}"
        inputs:
          targetType: inline
          script: |
            export USER_ID=`id -u`
            export USER_GROUP_ID=`id -g`
            eirctl infra:apply
        env:
          ARM_CLIENT_ID: $(ARM_CLIENT_ID)
          ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
          ARM_SUBSCRIPTION_ID: $(ARM_SUBSCRIPTION_ID)
          ARM_TENANT_ID: $(ARM_TENANT_ID)

      - task: CopyFiles@2
        displayName: Copy stage output files to staging area
        inputs:
          flattenFolders: true
          contents: $(Build.SourcesDirectory)/outputs/terraform/*${{ parameters.stage_name }}*
          targetFolder: $(Build.ArtifactStagingDirectory)/${{ parameters.stage_name }}

      - task: Bash@3
        displayName: "Ensure ${{ parameters.stage_name }} artifact directory exists"
        inputs:
          targetType: inline
          script: |
            mkdir -p $(Build.ArtifactStagingDirectory)/${{ parameters.stage_name }}
            echo "Staging directory prepared: $(Build.ArtifactStagingDirectory)/${{ parameters.stage_name }}"

      - task: PublishPipelineArtifact@1
        displayName: Upload Generated Files
        inputs:
          targetPath: $(Build.ArtifactStagingDirectory)/${{ parameters.stage_name }}
          artifact: ${{ parameters.stage_name }}

  - task: Bash@3
    displayName: "Docker: Save image to cache"
    condition: and(succeeded(), ne(variables.DOCKER_CACHE_RESTORED, 'true'))
    inputs:
      targetType: inline
      script: |
        mkdir -p $(Pipeline.Workspace)/.docker-cache
        echo "Saving Docker image to cache..."
        docker save ensono/eir-infrastructure:latest -o $(Pipeline.Workspace)/.docker-cache/eir-infrastructure.tar
        echo "Docker image cached successfully"
