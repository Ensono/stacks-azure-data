# Build and deploy pipeline for job Silver

name: "$(Build.SourceBranchName)-init"

pr:
  branches:
    include:
      - "main"
  paths:
    include:
      - de_workloads/data_processing/silver/*

trigger:
  branches:
    include:
      - "main"
  paths:
    include:
      - de_workloads/data_processing/silver/*

variables:
  - template: ../../../de_build/job-pipeline-vars.yml
  - template: ../../../build/version-data-vars.yml
  - name: job #update job name
    value: "silver"
  - name: jobtype #update job name
    value: "data_processing"
  - name: include_data_quality # update data quality option
    value: "true"
  - name: self_repo_job_dir
    value: "$(self_repo_dir)/de_workloads/$(jobtype)/$(job)"
  - name: self_repo_adf_dir
    value: "$(self_repo_job_dir)/data_factory"
  - name: test_unit_path
    value: "$(self_repo_job_dir)/tests/unit/"
  - name: test_end_to_end_path
    value: "$(self_repo_job_dir)/tests/end_to_end/features/"
  - name: junit_path
    value: "de_workloads/$(jobtype)/$(job)/junit/"
  - name: self_repo_sparkjob_dir
    value: "$(self_repo_job_dir)/spark_jobs"
  - name: self_repo_adf_src
    value: "de_workloads/$(jobtype)/$(job)/data_factory"
  - name: self_repo_spark_src  
    value: "de_workloads/$(jobtype)/$(job)/spark_jobs"
  - name: self_repo_blob_config
    value: "$(self_repo_job_dir)/config"
  - name: blob_config_destination
    value: "config/$(jobtype)/$(job)"
  - name: tf_state_key_dev
    value: $(domain)_$(jobtype)_$(job)_dev
  - name: tf_state_key_prod
    value: $(domain)_$(jobtype)_$(job)_prod
  - name: dbfs_destination  #update job name
    value: 'dbfs:/FileStore/scriptsTest'


pool:
  name: $(agentpool_name)

stages:
  - stage: Build_Stage
    variables:
      - group: amido-stacks-de-pipeline-nonprod
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
    jobs:
      - job: Build_Job
        displayName: "Build_Job"
        steps:
          - task: Bash@3
            displayName: "Clean Workspace"
            inputs:
              targetType: "inline"
              script: |
                echo "Cleaning workspace..."
                sudo rm -rf $(Build.SourcesDirectory)/*
                sudo rm -rf $(Build.SourcesDirectory)/.pytest_cache/*
                sudo rm -f $(Build.SourcesDirectory)/.pytest_cache/.gitignore


          - template: ../../../build/azDevOps/templates/air-infrastructure-data-setup.yml
            parameters:
              TaskctlVersion: ${{ variables.TaskctlVersion }}
          - script: |
              lastTag=$(git tag --sort=-creatordate | head -n 1)
              if [[ -z $lastTag ]]; then
                major=$(version_major)
                minor=$(version_minor)
                revision=$(version_revision)
                echo "Last Tag: NOT Present"
              else
                IFS='.' read -ra versionParts <<< "${lastTag#v}"
                major="${versionParts[0]}"
                minor="${versionParts[1]}"
                lastrevision="${versionParts[2]}"
                revision=$((lastrevision + 1))
                echo "Last Tag: $lastTag"
              fi
              newVersion="${major}.${minor}.${revision}"
              echo "New Version: $newVersion"
              echo "##vso[task.setvariable variable=major]$major"
              echo "##vso[task.setvariable variable=minor]$minor"
              echo "##vso[task.setvariable variable=revision]$revision"
              echo "##vso[task.setvariable variable=newVersion]$newVersion"
            displayName: Determine New Version
          - task: Bash@3
            displayName: "TaskCTL: Setup"
            inputs:
              targetType: inline
              script: taskctl setup
            env:
              DOCKER_IMAGE_TAG: $(newVersion)
          # - task: Bash@3
          #   displayName: "TaskCTL: Lint"
          #   inputs:
          #     targetType: inline
          #     script: taskctl lint
          #   env:
          #     # Dotnet Build
          #     CLOUD_PROVIDER: "$(cloud_provider)"
          #     ARM_TENANT_ID: "$(azure-tenant-id)"
          #     ARM_SUBSCRIPTION_ID: "$(azure-subscription-id)"
          #     ARM_CLIENT_ID: "$(azure-client-id)"
          #     ARM_CLIENT_SECRET: "$(azure-client-secret)"
          #     TF_FILE_LOCATION: ./$(jobtype)/jobs/$(job)/

  #############################################################
  # Deploy to non Prod
  #############################################################
  - stage: Deploy_NonPROD_Stage
    variables:
      - group: amido-stacks-de-pipeline-nonprod
      - group: amido-stacks-infra-credentials-nonprod
      - group: stacks-credentials-nonprod-kv
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
    dependsOn: Build_Stage
    jobs:
      - deployment: Deploy_NonPROD
        displayName: "Deploy To NonPROD"
        environment: ${{ variables.domain }}-nonprod
        pool:
          name: $(agentpool_name)

        strategy:
          runOnce:
            deploy:
              steps:
                - task: Bash@3
                  displayName: "Clean Workspace"
                  inputs:
                    targetType: "inline"
                    script: |
                      echo "Cleaning workspace..."
                      sudo rm -rf $(Build.SourcesDirectory)/*

                - template: ../../../build/azDevOps/templates/air-infrastructure-data-setup.yml
                  parameters:
                    TaskctlVersion: ${{ variables.TaskctlVersion }}
                - script: dir
                  displayName: List  Workspace
                  workingDirectory: '$(System.DefaultWorkingDirectory)'

                # Publish Config files
                # - task: AzureCLI@2
                #   inputs:
                #     # TODO: Remove hardcoded reference to subscription
                #     azureSubscription: "Stacks.Pipeline.Builds"
                #     scriptType: "pscore"
                #     scriptLocation: "inlineScript"
                #     inlineScript: "az storage blob upload-batch `
                #       --source $(self_repo_blob_config) `
                #       --destination $(blob_config_destination) `
                #       --account-name $(blob_configStorage) `
                #       --overwrite"

                # - task: AzureKeyVault@2
                #   inputs:
                #     azureSubscription: "Stacks.Pipeline.Builds"
                #     KeyVaultName: $(keyvault_name)
                #     SecretsFilter: "*"
                #     RunAsPreJob: false
                #   displayName: "Get secrets from the keyvault"

                # - task: Bash@3
                #   displayName: "TaskCTL: Databricks"
                #   inputs:
                #     targetType: inline
                #     script: taskctl databricks
                #   env:
                #     # Dotnet Build
                #     DATABRICKS_HOST: "$(databricks-host)"
                #     DATABRICKS_TOKEN: "$(databricks-token)"
                #     DATABRICKS_DBFS_LOCATION: "$(dbfs_destination)"    #self_repo_spark_src
                #     DATABRICKS_SOURCE_LOCATION: "./$(self_repo_spark_src)/"

                # # Publish ADF
                # - task: Bash@3
                #   displayName: "TaskCTL: infrastructure"
                #   inputs:
                #     targetType: inline
                #     script: taskctl -d infrastructure
                #   env:
                #     # Dotnet Build
                #     CLOUD_PROVIDER: "$(cloud_provider)"
                #     ARM_TENANT_ID: "$(azure-tenant-id)"
                #     ARM_SUBSCRIPTION_ID: "$(azure-subscription-id)"
                #     ARM_CLIENT_ID: "$(azure-client-id)"
                #     ARM_CLIENT_SECRET: "$(azure-client-secret)"
                #     TF_FILE_LOCATION: "./$(self_repo_adf_src)/"
                #     ENV_NAME:
                #       $(Environment.ShortName)
                #       # Azure Authentication
                #       # Terraform Backend Configuration
                #     TF_STATE_CONTAINER: $(tf_state_container)
                #     TF_STATE_KEY: $(tf_state_key_dev)
                #     TF_STATE_RG: $(tf_state_rg)
                #     TF_STATE_STORAGE: $(tf_state_storage)
                #     TF_BACKEND_ARGS: "key=$(tf_state_key_dev),storage_account_name=$(TF_STATE_STORAGE),resource_group_name=$(TF_STATE_RG),container_name=$(TF_STATE_CONTAINER),subscription_id=$(azure-subscription-id),tenant_id=$(azure-tenant-id),client_id=$(azure-client-id),client_secret= $(azure-client-secret)"
                #     TF_VAR_data_factory_resource_group_name: $(resource_group)
                #     TF_VAR_data_factory: $(datafactoryname)
                #     TF_VAR_include_data_quality: "$(include_data_quality)"

      #   # Start Testing
      - deployment: Test_NonPROD
        displayName: "Testing  NonPROD"
        environment: ${{ variables.domain }}-nonprod
        dependsOn: Deploy_NonPROD
        pool:
          name: $(agentpool_name)
        strategy:
          runOnce:
            deploy:
              steps:
                # - task: AzureCLI@2
                #   inputs:
                    # TODO: Remove hardcoded reference to subscription
                #     azureSubscription: "Stacks.Pipeline.Builds"
                #     ScriptType: "bash"
                #     scriptLocation: "inlineScript"
                #     inlineScript: az account show
                - task: UsePythonVersion@0
                  inputs:
                    versionSpec: "$(pythonVersion)"
                    githubToken: "$(github_token)"
                    addToPath: true

                  displayName: Set Python Version
                
                # - task: Bash@3
                #   displayName: "TaskCTL: deworkloadTesting"
                #   inputs:
                #     targetType: inline
                #     script: taskctl deworkloadTesting
                #   env:
                #     # Dotnet Build
                #     GITHUB_TOKEN: "$(github_token)"
                #     PYTHON_VERSION: "$(pythonVersion)"
                #     PYPROJECT_LOCATION: "./"    #$(self_repo_dir)
                #     UNIT_TESTING_LOCATION: "./de_workloads/data_processing/silver/tests/unit/"
                #     JUNIT_LOCATION: "$(junit_path)"

                # - task: UsePythonVersion@0
                #   inputs:
                #     versionSpec: "$(pythonVersion)"
                #     githubToken: "$(github_token)"
                #     addToPath: true

                #   displayName: Set Python Version

                # - bash: |
                #     pip install pytest pylint pylint-exit pytest-azurepipelines pytest-cov poetry
                #   displayName: "Install Pipeline Tools"
                # - bash: |
                #     poetry install
                #   displayName: "Running poetry install"
                #   workingDirectory: "$(self_repo_dir)"
                # - bash: |
                #     python -m pytest $(test_unit_path)
                #   displayName: "Running py test"
                #   workingDirectory: "$(self_repo_dir)"

                # # TODO: Add e2e tests for silver
                # # - bash: |
                # #     poetry run behave $(test_end_to_end_path)  --junit --junit-directory $(junit_path)
                # #   displayName: "Running e2e Test"
                # #   workingDirectory: "$(self_repo_dir)"
                # #   env:
                # #     AZURE_SUBSCRIPTION_ID: $(azure_subscription_id)
                # #     AZURE_RESOURCE_GROUP_NAME: $(resource_group)
                # #     AZURE_DATA_FACTORY_NAME: $(datafactoryname)
                # #     AZURE_REGION_NAME: $(region)
                # #     AZURE_STORAGE_ACCOUNT_NAME: $(blob_adls_storage)
                # #     AZURE_CLIENT_ID: $(azure-client-id)
                # #     AZURE_CLIENT_SECRET: $(azure-client-secret)
                # #     AZURE_TENANT_ID: $(azure-tenant-id)
                - script: dir
                  displayName: List  Workspace
                  workingDirectory: '$(System.DefaultWorkingDirectory)'

                - task: PublishTestResults@2
                  displayName: "Publish Test Results"
                  inputs:
                    testResultsFiles: "**/*.xml"
                    searchFolder: ./app #$(junit_path)
                  condition: succeededOrFailed()


  #############################################################
  # Deploy to Prod
  #############################################################
  - stage: Deploy_Prod_Stage
    dependsOn:
      - Build_Stage
      - Deploy_NonPROD_Stage
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    variables:
      - group: amido-stacks-de-pipeline-prod
      - group: stacks-credentials-prod-kv
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
      - name: Environment.ShortName
        value: prod
    jobs:
      - deployment: Deploy_PRDO
        displayName: "Deploy To PROD"
        environment: ${{ variables.domain }}-prod
        pool:
          name: $(agentpool_name)

        strategy:
          runOnce:
            deploy:
              steps:
                - task: Bash@3
                  displayName: "Clean Workspace"
                  inputs:
                    targetType: "inline"
                    script: |
                      echo "Cleaning workspace..."
                      sudo rm -rf $(Build.SourcesDirectory)/*

                - template: ../../../build/azDevOps/templates/air-infrastructure-data-setup.yml
                  parameters:
                    TaskctlVersion: ${{ variables.TaskctlVersion }}

                # Publish Config files
                - task: AzureCLI@2
                  inputs:
                    # TODO: Remove hardcoded reference to subscription
                    azureSubscription: "Stacks.Pipeline.Builds"
                    scriptType: "pscore"
                    scriptLocation: "inlineScript"
                    inlineScript: "az storage blob upload-batch `
                      --source $(self_repo_blob_config) `
                      --destination $(blob_config_destination) `
                      --account-name $(blob_configStorage) `
                      --overwrite"

                - task: AzureKeyVault@2
                  inputs:
                    azureSubscription: "Stacks.Pipeline.Builds"
                    KeyVaultName: $(keyvault_name)
                    SecretsFilter: "*"
                    RunAsPreJob: false
                  displayName: "Get secrets from the keyvault"

                - task: Bash@3
                  displayName: "TaskCTL: Databricks"
                  inputs:
                    targetType: inline
                    script: taskctl databricks
                  env:
                    # Dotnet Build
                    DATABRICKS_HOST: "$(databricks-host)"
                    DATABRICKS_TOKEN: "$(databricks-token)"
                    DATABRICKS_DBFS_LOCATION: "$(dbfs_destination)"    #self_repo_spark_src
                    DATABRICKS_SOURCE_LOCATION: "./$(self_repo_spark_src)/"

                # Publish ADF
                - task: Bash@3
                  displayName: "TaskCTL: infrastructure"
                  inputs:
                    targetType: inline
                    script: taskctl infrastructure
                  env:
                    # Dotnet Build
                    CLOUD_PROVIDER: "$(cloud_provider)"
                    ARM_TENANT_ID: "$(azure-tenant-id)"
                    ARM_SUBSCRIPTION_ID: "$(azure-subscription-id)"
                    ARM_CLIENT_ID: "$(azure-client-id)"
                    ARM_CLIENT_SECRET: "$(azure-client-secret)"
                    TF_FILE_LOCATION: "./$(self_repo_adf_src)/"
                    ENV_NAME:
                      $(Environment.ShortName)
                      # Azure Authentication
                      # Terraform Backend Configuration
                    TF_STATE_CONTAINER: $(tf_state_container)
                    TF_STATE_KEY: $(tf_state_key)
                    TF_STATE_RG: $(tf_state_rg)
                    TF_STATE_STORAGE: $(tf_state_storage)
                    TF_BACKEND_ARGS: "key=$(tf_state_key),storage_account_name=$(TF_STATE_STORAGE),resource_group_name=$(TF_STATE_RG),container_name=$(TF_STATE_CONTAINER),subscription_id=$(azure-subscription-id),tenant_id=$(azure-tenant-id),client_id=$(azure-client-id),client_secret= $(azure-client-secret)"
                    TF_VAR_data_factory_resource_group_name: $(resource_group)
                    TF_VAR_data_factory: $(datafactoryname)
                    TF_VAR_include_data_quality: "$(include_data_quality)"

  - stage: Release
    dependsOn:
      - Build_Stage
      - Deploy_Prod_Stage
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'), eq(variables['create_release'], 'true'))
    variables:
      - group: amido-stacks-infra-credentials-nonprod
      # - name: version_number
      #   value: "$(version_major).$(version_minor).$(version_revision)"
    jobs:
      - job: CreateGitHubRelease
        pool:
          name: $(agentpool_name)
        steps:
          - task: Bash@3
            displayName: "Clean Workspace"
            inputs:
              targetType: "inline"
              script: |
                echo "Cleaning workspace..."
                sudo rm -rf $(Build.SourcesDirectory)/*
          # Check out the repo so that it can be tagged
          - checkout: self
            persistCredentials: true

          - script: |
              lastTag=$(git tag --sort=-creatordate | head -n 1)
              if [[ -z $lastTag ]]; then
                major=$(version_major)
                minor=$(version_minor)
                revision=$(version_revision)
                echo "Last Tag: NOT Present"
              else
                IFS='.' read -ra versionParts <<< "${lastTag#v}"
                major="${versionParts[0]}"
                minor="${versionParts[1]}"
                lastrevision="${versionParts[2]}"
                revision=$((lastrevision + 1))
                echo "Last Tag: $lastTag"
              fi
              newVersion="${major}.${minor}.${revision}"
              echo "New Version: $newVersion"
              echo "##vso[task.setvariable variable=major]$major"
              echo "##vso[task.setvariable variable=minor]$minor"
              echo "##vso[task.setvariable variable=revision]$revision"
              echo "##vso[task.setvariable variable=newVersion]$newVersion"
            displayName: Determine New Version

          - task: Bash@3
            displayName: Tag Code
            inputs:
              targetType: "inline"
              script: |
                commit=$(Build.SourceVersion)
                tag=$(git tag --contains $commit)
                if [ -z "$tag" ]; then
                  echo "Tag does not exist for the commit"
                  git config user.name "BuildService"
                  git config user.email "builder@${COMPANY}.com"
                  echo "Creating tag v${newVersion}..."
                  git tag -a "v${newVersion}" -m "Release created by Azure DevOps"
                  git push origin "v${newVersion}"
                  echo "##vso[task.setvariable variable=ShouldCreateRelease]True"
                else
                  echo "Tag '$tag' already exists for the commit.Skipping tag creation"
                  echo "##vso[task.setvariable variable=ShouldCreateRelease]false"
                fi
            env:
              COMPANY: $(company)
              newVersion: $(newVersion)

          # #           # Create a GitHub release with these packages
          - task: GitHubRelease@1
            displayName: Create GitHub Release
            inputs:
              gitHubConnection: $(github_release_service_connection)
              repositoryName: $(github_org)/$(self_repo)
              tag: v${newVersion}
              releaseNotesSource: "inline"
              releaseNotesInline: "$(major).$(minor).$(revision)"
              tagSource: "gitTag"
              changeLogCompareToRelease: "lastFullRelease"
              changeLogType: "commitBased"
            condition: eq(variables['ShouldCreateRelease'], 'true')
