# Starter pipeline
# Start with a minimal pipeline that you can customize to build and deploy your code.
# Add steps that build, run tests, deploy, and more:
# https://aka.ms/yaml

# Sample YAML file to validate and export an ARM template into a build artifact
# Requires a package.json file located in the target repository

name: "$(Build.SourceBranchName)-init"


pr:
  - main

trigger:
  branches:
   
    include:
      - 'main'
  paths:
    include:
      - data_quality/jobs/examplejob_copy/adfpipeline/*
      - data_quality/jobs/examplejob_copy/tests/*
      - data_quality/jobs/examplejob_copy/generate-ingest-query.yml


variables:
  - template: ../../../de_build/job-pipeline-vars.yml
  - template: ../../../de_build/air-data-testing-vars.yml
  - name: job  #update job name
    value: 'Generate_Ingest_Query'
  - name: jobtype  #update job name
    value: 'data_quality'
  - name: self_repo_adf_dir
    value: "$(self_repo_dir)/$(jobtype)/jobs/$(job)/adfpipeline"
  - name: test_unit_path
    value: '$(self_repo_dir)/$(jobtype)/jobs/$(job)/tests/unit/'
  - name: test_end_to_end_path
    value: '$(self_repo_dir)/$(jobtype)/jobs/$(job)/tests/end_to_end/features/'
  - name: junit_path
    value: '$(self_repo_dir)/$(jobtype)/jobs/$(job)/junit/'
  - name: self_repo_sparkjob_dir
    value: "$(self_repo_dir)/$(jobtype)/jobs/$(job)/spark-jobs"

pool:
  name: $(agentpool_name)


stages:
- stage: Build_Stage
  variables:
      - group: amido-stacks-de-pipeline-nonprod
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
  jobs:
   - template: ../../../de_build/build-dataquality-job.yml
     parameters:
      self_repo_dir: '$(self_repo_dir)'
      self_repo_adf_dir: '$(self_repo_adf_dir)'
      self_repo_sparkjob_dir: '$(self_repo_sparkjob_dir)'

#############################################################
# Deploy to non Prod
#############################################################
- stage: Deploy_NonPROD_Stage
  variables:
      - group: amido-stacks-de-pipeline-nonprod
      - group: amido-stacks-infra-credentials-nonprod
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
  dependsOn: Build_Stage
  jobs:
  - deployment: Deploy_NonPROD
    displayName: 'Deploy To NonPROD'
    environment: ${{ variables.domain }}-nonprod
    pool:
      name: $(agentpool_name)

    strategy:
      runOnce:
        deploy:  
          steps:

           - task: DownloadPipelineArtifact@2
             displayName: Download Build Artifacts
             inputs:
              targetPath: '$(System.DefaultWorkingDirectory)'

           - script: dir
             displayName: List ArmTemplates Artifact in Workspace
             workingDirectory: '$(System.DefaultWorkingDirectory)/ArmTemplates'

           - script: dir
             displayName: List ArmTemplates SparkJob in Workspace
             workingDirectory: '$(System.DefaultWorkingDirectory)/SparkJob'

           - script: pip install databricks-cli
             displayName: Install Databricks CLI
             
           - script: |
                      echo "$(databricks-host)
                      $(databricks-token)" | databricks configure --token
             displayName: Configure databricks-cli

           - script: |
                      databricks workspace ls
                      databricks fs ls
             displayName: test databricks-cli

           - script: |
                     echo Destination is /FileStore
                     echo Source is $(System.DefaultWorkingDirectory)/SparkJob
                     databricks fs cp -r --overwrite $(System.DefaultWorkingDirectory)/SparkJob/*.* dbfs:/FileStore/
             displayName: Upload Spark Job             
            
          #  - task: AzureCLI@2
          #    inputs:
          #      azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
          #      scriptType: 'pscore'
          #      scriptLocation: 'inlineScript'
          #      inlineScript: 'az deployment group what-if `
          #                     --resource-group $(resource_group) `
          #                     --template-file $(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json `
          #                     --parameters $(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateParametersForFactory.json `
          #                     --parameters factoryName=amido-stacks-dev-euw-de  `
          #                     --exclude-change-types Ignore'        

    # Publish ADF
           - task: AzurePowerShell@5
             displayName: 'Stop ADF triggers'
             inputs:
              azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.DefaultWorkingDirectory)/ArmTemplates/PrePostDeploymentScriptLatest.ps1'
              ScriptArguments:  -armTemplate "$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json"
                              -ResourceGroupName $(resource_group)
                              -DataFactoryName $(datafactoryname)
                              -predeployment $true
                              -deleteDeployment $false
              azurePowerShellVersion: 'LatestVersion'

           - task: AzureResourceManagerTemplateDeployment@3
             displayName: 'ARM Template deployment: Resource Group scope'
             inputs:
                azureResourceManagerConnection: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
                subscriptionId: '$(azure_subscription_id)'
                resourceGroupName: $(resource_group)
                location: $(region)
                csmFile: '$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json'
                csmParametersFile: '$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateParametersForFactory.json'
                overrideParameters: -factoryName $(datafactoryname)
                deploymentMode: 'Incremental'

           - task: AzurePowerShell@5
             displayName: 'Clean resources and start ADF triggers'
             inputs:
              azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.DefaultWorkingDirectory)/ArmTemplates/PrePostDeploymentScriptLatest.ps1'
              ScriptArguments:  -armTemplate "$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json"
                              -ResourceGroupName $(resource_group)
                              -DataFactoryName $(datafactoryname)
                              -predeployment $false
                              -deleteDeployment $false
              azurePowerShellVersion: 'LatestVersion'

    # Start Testing 
  - deployment: Test_NonPROD
    displayName: 'Testing  NonPROD'
    environment: ${{ variables.domain }}-nonprod
    dependsOn: Deploy_NonPROD
    pool:
      name: $(agentpool_name)
    strategy:
      runOnce:
        deploy:  
          steps:
           - checkout: self
           - task: AzureCLI@2
             inputs:
               azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
               ScriptType: 'bash'
               scriptLocation: 'inlineScript'
               inlineScript: az account show 
           
           - task: UsePythonVersion@0
             inputs:
                versionSpec: '$(pythonVersion)'
                githubToken: '$(github_token)'
                addToPath: true

             displayName: Set Python Version

           - bash: |
              pip install pytest pylint pylint-exit pytest-azurepipelines pytest-cov poetry
             displayName: 'Install Pipeline Tools'
           - bash: |
              poetry install 
             displayName: 'Running poetry install'
             workingDirectory:  '$(self_repo_dir)'
           - bash: |
               python -m pytest $(test_unit_path)
             displayName: 'Running py test'
             workingDirectory:  '$(self_repo_dir)'

           - bash: |
               poetry run behave $(test_end_to_end_path)  --junit --junit-directory $(junit_path)
             displayName: 'Running e2e Test'
             workingDirectory:  '$(self_repo_dir)'
             env:
                  AZURE_SUBSCRIPTION_ID: $(azure_subscription_id)
                  AZURE_RESOURCE_GROUP_NAME: $(resource_group)
                  AZURE_DATA_FACTORY_NAME: $(datafactoryname)
                  AZURE_REGION_NAME: $(region)
                  AZURE_STORAGE_ACCOUNT_NAME: $(blob_adls_storage)
                  AZURE_CLIENT_ID: $(azure-client-id)
                  AZURE_CLIENT_SECRET: $(azure-client-secret)
                  AZURE_TENANT_ID: $(azure-tenant-id)   

           - task: PublishTestResults@2
             displayName: 'Publish Test Results'
             inputs:
                testResultsFiles: '**/*.xml'
                searchFolder: $(junit_path)
             condition: succeededOrFailed()
  

#############################################################
# Deploy to Prod
#############################################################
- stage: Deploy_Prod_Stage
  dependsOn: 
    - Build_Stage
    - Deploy_NonPROD_Stage
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  variables:
      - group: amido-stacks-de-pipeline-prod
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
  jobs:
  - deployment: Deploy_PRDO
    displayName: 'Deploy To PROD'
    environment: ${{ variables.domain }}-prod
    pool:
      name: $(agentpool_name)

    strategy:
      runOnce:
        deploy:  
          steps:


           - task: DownloadPipelineArtifact@2
             displayName: Download Build Artifacts
             inputs:
              targetPath: '$(System.DefaultWorkingDirectory)'

           - script: dir
             displayName: List ArmTemplates Artifact in Workspace
             workingDirectory: '$(System.DefaultWorkingDirectory)/ArmTemplates'
  
             - script: dir
             displayName: List ArmTemplates SparkJob in Workspace
             workingDirectory: '$(System.DefaultWorkingDirectory)/SparkJob'

           - script: pip install databricks-cli
             displayName: Install Databricks CLI
             
           - script: |
                      echo "$(databricks-host)
                      $(databricks-token)" | databricks configure --token
             displayName: Configure databricks-cli

           - script: |
                      databricks workspace ls
                      databricks fs ls
             displayName: test databricks-cli

           - script: |
                     echo Destination is /FileStore
                     echo Source is $(System.DefaultWorkingDirectory)/SparkJob
                     databricks fs cp -r --overwrite $(System.DefaultWorkingDirectory)/SparkJob/*.* dbfs:/FileStore/
             displayName: Upload Spark Job   

    # Publish ADF
           - task: AzurePowerShell@5
             displayName: 'Stop ADF triggers'
             inputs:
              azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.DefaultWorkingDirectory)/ArmTemplates/PrePostDeploymentScriptLatest.ps1'
              ScriptArguments:  -armTemplate "$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json"
                              -ResourceGroupName $(resource_group)
                              -DataFactoryName $(datafactoryname)
                              -predeployment $true
                              -deleteDeployment $false
              azurePowerShellVersion: 'LatestVersion'

           - task: AzureResourceManagerTemplateDeployment@3
             displayName: 'ARM Template deployment: Resource Group scope'
             inputs:
                azureResourceManagerConnection: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
                subscriptionId: '$(azure_subscription_id)'
                resourceGroupName: $(resource_group)
                location: $(region)
                csmFile: '$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json'
                csmParametersFile: '$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateParametersForFactory.json'
                overrideParameters: -factoryName $(datafactoryname)
                deploymentMode: 'Incremental'

           - task: AzurePowerShell@5
             displayName: 'Clean resources and start ADF triggers'
             inputs:
              azureSubscription: 'amido.stacks (719637e5-aedd-4fb1-b231-5101b45f8bb5)'
              ScriptType: 'FilePath'
              ScriptPath: '$(System.DefaultWorkingDirectory)/ArmTemplates/PrePostDeploymentScriptLatest.ps1'
              ScriptArguments:  -armTemplate "$(System.DefaultWorkingDirectory)/ArmTemplates/ARMTemplateForFactory.json"
                              -ResourceGroupName $(resource_group)
                              -DataFactoryName $(datafactoryname)
                              -predeployment $false
                              -deleteDeployment $false
              azurePowerShellVersion: 'LatestVersion'
 
- stage: Release
  dependsOn:
      - Build_Stage
      - Deploy_Prod_Stage
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'), eq(variables['create_release'], 'true'))
  variables:
      - group: amido-stacks-infra-credentials-nonprod
      - name: version_number
        value: "$(version_major).$(version_minor).$(version_revision)"
  jobs:
      - job: CreateGitHubRelease
        pool:
          name: $(agentpool_name)
        steps:
          # Check out the repo so that it can be tagged
          - checkout: self
            persistCredentials: true

          # Create a tag in the code for this release
          - task: Bash@3
            displayName: Tag Code
            inputs:
              targetType: "inline"
              script: |
                git config user.name "BuildService"
                git config user.email "builder@${COMPANY}.com"
                git tag -a v${VERSION_NUMBER} -m "Release created by Azure DevOps"
                git push origin v${VERSION_NUMBER}
            env:
              COMPANY: $(company)

          # Create a GitHub release with these packages
          - task: GitHubRelease@1
            displayName: Create GitHub Release
            inputs:
              gitHubConnection: $(github_release_service_connection)
              repositoryName: $(github_org)/$(self_repo)
              tag: v${VERSION_NUMBER}
              releaseNotesSource: 'inline'
              releaseNotesInline: "$(version_major).$(version_minor).$(version_revision)"
              tagSource: 'gitTag'
              changeLogCompareToRelease: 'lastFullRelease'
              changeLogType: 'commitBased'
